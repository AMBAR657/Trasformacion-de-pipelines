{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa3b202",
   "metadata": {},
   "source": [
    "# REGRESION LGISTICA DETECCION DE SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e5b79",
   "metadata": {},
   "source": [
    "en este ejersici se muestra los fundamentos de la regrecion logistica planteando uno de los primeros problemas que fueron solucionados mediante tecnicas de machinlearning: Deteccion de SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34296144",
   "metadata": {},
   "source": [
    "## enunciado del ejersicio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b87bc",
   "metadata": {},
   "source": [
    "se propone la construccion de un sistema automatico capaz de predecir si un correo determinado es un correo SPAM o no para ello se utilizara el siguiente Dataset \n",
    "\n",
    "[2007 TREC Public Spam corpus](https://terabox.com/s/1QwAgmiBvDVTBspietF6K8w)\n",
    "\n",
    "la carpeta contiene 75,419 mensajes de correo electronico \n",
    "\n",
    "25220 son HAM\n",
    "50199 son SPAM \n",
    "\n",
    "These messages constitute al the messages delivered to aparticula server bitwween these dates:/*312\n",
    "\n",
    "sun, 8 Appr 2007 13:07:21 - 0400\n",
    "fri 6 jul 2007 07:04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7947a2a6",
   "metadata": {},
   "source": [
    "* Aprendizaje **supervisado**.\n",
    "* Aprendizaje basado en modelos**\n",
    "* se corresponde con un **modelo lineal generalizadp.\n",
    "* realiza predicciones computando una **suama ponderada de las caracteristicas de entrada** sumandole una constante conocida como bias, pero se aplica una funcion logistica al resultado "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068da00",
   "metadata": {},
   "source": [
    "## Funciones complementarias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee9b05",
   "metadata": {},
   "source": [
    "En este caso práctico con la deteccion de correos electronicos SPAM, el conjunto de datos de que se dispone esta tomado por correos electronicos con sus correcpondientes cabeceras y campos adicionales por lo tanto se requieren de un procesamiento previo a que sean injeridos por el algoritmo de Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635f721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta clase facilita el preprocesamiento de correos electronicos que possen codigo HTML\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "        \n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "        \n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5d3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que se encargara de eliminar tags html que se encuentren en el texto del correo \n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683e8b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phrack World News'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ejemplo de eliminacion de los tags HTML de un texto \n",
    "t = '<tr><td align    =\"left\"><a href=\"../../issues/51/16.html#article\">Phrack World News</a></td>'\n",
    "strip_tags(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc87a59",
   "metadata": {},
   "source": [
    "Ademas de eliminar los posibles tags HTML que se encuentren en el correo electronico deben\n",
    "realizarse otras acciones de procesamiento para evitar que los mensajes contengan ruido\n",
    "necesario, entre ellas se encuentra la eliminacion de los signos de puntuacion, eliminacion \n",
    "de posibles campos de correo electronico que no son relevantes o eliminacion de los afijos de una palabra\n",
    "manteniendo unicaamente la raiz de la misma (Stemming). La clase que se muestra a continuacion realiza estas transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bdfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import string\n",
    "import nltk \n",
    "\n",
    "class Parser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer = nltk.PorterStemmer()\n",
    "        self.stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "        self.punctuation = list(string.punctuation)\n",
    "       \n",
    "    def parse(self, email_path):\n",
    "        \"\"\"Parse an email.\"\"\"\n",
    "        with open(email_path, errors = 'ignore') as e:\n",
    "            msg = email.message_from_file(e)\n",
    "        return None if not msg else self.get_email_content(msg)\n",
    "    \n",
    "    def get_email_content(self, msg):\n",
    "        \"\"\"Exctact the email content.\"\"\" \n",
    "        \n",
    "        subject = self.tokenize(msg['Subject']) if msg['subject'] else []\n",
    "        body = self.get_email_body(msg.get_payload(),\n",
    "                                  msg.get_content_type())\n",
    "        content_type = msg.get_content_type()\n",
    "        #retornar el content del email \n",
    "        return{\"subject\": subject,\n",
    "               \"body\": body,\n",
    "               \"content_type\":content_type}\n",
    "  \n",
    "    def get_email_body(self, payload, content_type):\n",
    "        \"\"\"Extract the body of email.\"\"\"\n",
    "        body = []\n",
    "        if type(payload) is str and content_type =='text/plain':\n",
    "            return self.tokenize(payload) \n",
    "        elif type(payload) is str and content_type =='text/html':\n",
    "            return self.tokenize(strip_tags(payload))\n",
    "                                 \n",
    "        elif type(payload) is list: \n",
    "            for p in payload:\n",
    "                body += self.get_email_body(p.get_payload(),\n",
    "                                        p.get_content_type())\n",
    "        return body \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Transform a text string in tokens. Perform two main actions,\n",
    "        clean the punctuation symbols and do stemming of the text.\"\"\"\n",
    "        for c in self.punctuation:\n",
    "            text = text.replace(c, \"\")\n",
    "        text = text.replace(\"\\t\", \" \")\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        tokens = list(filter(None, text.split(\" \")))\n",
    "                                 #stemming of the tokens\n",
    "        return [self.stemmer.stem (w) for w in tokens if w not in self.stopwords]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ed95d",
   "metadata": {},
   "source": [
    "## Lectura de un correo en formato RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469f3ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/trec07p/data/inmail.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inmail \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/trec07p/data/inmail.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(inmail)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/trec07p/data/inmail.1'"
     ]
    }
   ],
   "source": [
    "inmail = open(\"datasets/trec07p/data/inmail.1\").read()\n",
    "print(inmail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf47fad",
   "metadata": {},
   "source": [
    "#### Parsing del correo electronico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def07e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "p = Parser()\n",
    "p.parse (\"datasets/trec07p/data/inmail.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec4bcf",
   "metadata": {},
   "source": [
    "#### lectura del indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fee78",
   "metadata": {},
   "source": [
    "esta funcion complementaria se encarga de cargar en memoria la ruta de cada correo electronico y su etiqueta correspondiente {spam,ham}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = open(\"datasets/trec07p/full/index\").readlines()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fe172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "DATASET_PATH = 'datasets/trec07p'\n",
    "def parse_index(path_to_index, n_elements):\n",
    "    ret_indexes = []\n",
    "    index = open(path_to_index).readlines()\n",
    "    for i in range(n_elements):\n",
    "        mail = index[i].split(\"../\")\n",
    "        label = mail[0]\n",
    "        path = mail[1][:-1]\n",
    "        ret_indexes.append({\"label\":label, \"email_path\":os.path.join(DATASET_PATH, path)})\n",
    "    return ret_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a28928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(index):\n",
    "    p= Parser()\n",
    "    pmail = p.parse(index[\"email_path\"])\n",
    "    return pmail, index [\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes= parse_index(\"datasets/trec07p/full/index\", 10)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608b9b5",
   "metadata": {},
   "source": [
    "### Pre procesamiento de los datos del set de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435803",
   "metadata": {},
   "source": [
    "con las funciones precentadas anteriormente se permite la lectura de los correos electronicos de manera programatica y el procesamiento de los mismos para eliminar quellos componenetes que no son de utilidad para la deteccion de los correos spam sin embargo cada uno de los correos sige estando reprecentado por un diccionario de python con una serie de palabras.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6870576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el indice y las etiquetas en memoria \n",
    "index = parse_index(\"datasets/trec07p/full/index\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa768d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer el primer correo electronico \n",
    "import os \n",
    "\n",
    "open (index[0][\"email_path\"]).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsear el primer correo \n",
    "mail, label = parse_email(index[0])\n",
    "print(\"el correo es:\", label)\n",
    "print(mail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ac8f4",
   "metadata": {},
   "source": [
    "El algoritmo de regreción logística no es capaz de ingerir texto como parte del conjunto de datos de los correos electrinicos parseados en una representacion numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bebd7",
   "metadata": {},
   "source": [
    "##### Aplicación de CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9c045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58d7166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e-mail:  ['subject_textbody_text'] \n",
      "\n",
      "Características de entrada:  ['subject_textbody_text']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Asumiendo que email y mail son objetos válidos\n",
    "email = {\n",
    "    \"subject\": [\"subject_text\"],\n",
    "    \"body\": [\"body_text\"]\n",
    "}\n",
    "\n",
    "prep_email = [\" \".join(email[\"subject\"]) + \" \".join(email[\"body\"])]\n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit(prep_email)\n",
    "\n",
    "print(\"e-mail: \", prep_email, \"\\n\")\n",
    "print(\"Características de entrada: \", vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0547227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Values: \n",
      " [[1]]\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.transform(prep_email)\n",
    "print(\"\\nValues: \\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa04d9",
   "metadata": {},
   "source": [
    "#### Aplicación de OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3dfbb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " ['x0_body_text' 'x0_subject_text']\n",
      "\n",
      "Values:\n",
      " [[0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Definir la variable 'mail' con los datos adecuados\n",
    "mail = {\n",
    "    'subject': ['subject_text'],\n",
    "    'body': ['body_text']\n",
    "}\n",
    "\n",
    "prep_email = [[w] for w in mail['subject'] + mail['body']]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = enc.fit_transform(prep_email)\n",
    "\n",
    "print(\"Features:\\n\", enc.get_feature_names_out())\n",
    "print(\"\\nValues:\\n\", X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be05b3",
   "metadata": {},
   "source": [
    "##### Fuciones auxiloares para el preprocesamiento del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b46b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prep_dataset(index_path, n_elements):\n",
    "    x = []\n",
    "    y = []\n",
    "    indexes = parse_index(index_path, n_elements)\n",
    "    for i in range(n_elements):\n",
    "        print(\"\\rParsing email: {0}\".format(i+1), end = '')\n",
    "        mail, label = parse_email(indexes[i])\n",
    "        x.append(\" \".join(mail['subject']) + \" \".join(mail['body']))\n",
    "        y.append(label)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab4108b",
   "metadata": {},
   "source": [
    "## 3.- Entenamiento del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b97ea65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Leer únicamente un subconnunto de 100 correos electrónicos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_train, y_train \u001b[38;5;241m=\u001b[39m create_prep_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/trec07p/full/index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m x_train\n",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mcreate_prep_dataset\u001b[0;34m(index_path, n_elements)\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m indexes \u001b[38;5;241m=\u001b[39m parse_index(index_path, n_elements)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_elements):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mParsing email: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Leer únicamente un subconnunto de 100 correos electrónicos\n",
    "x_train, y_train = create_prep_dataset(\"datasets/trec07p/full/index\", 100)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa090908",
   "metadata": {},
   "source": [
    "#####  Vectorización de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e58f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.toarray())\n",
    "print(\"\\nFeature:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3b317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(x_train.toarray(), columns=[vectorizer.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39bdff",
   "metadata": {},
   "source": [
    "##### Entrenamiento de regrecion logistica con el conjunto de datos procesados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716888cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872c09b",
   "metadata": {},
   "source": [
    "#### 4.- Predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a879ad",
   "metadata": {},
   "source": [
    "#### Lectura del conjunto de correos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04840a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer 150 correos del datset y quedarse únicamente con los 50 últimos, estos 50 coreos electrónicosno se han utilizado para entrenar el algoritmo.\n",
    "x,y = create_prep_dataset(\"datasets/trec07p/full/index\", 150)\n",
    "x_test = x[100:]\n",
    "y_test = y[100:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513db479",
   "metadata": {},
   "source": [
    "##### Preprocesamiento de los correos con el vectorizador creado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df4631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005d871",
   "metadata": {},
   "source": [
    "#### Prediccion del tipo de correo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e91b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicción: \\n\",y_pred)\n",
    "print(\"Etiquetas Reales: \\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a74eb0",
   "metadata": {},
   "source": [
    "##### Evaluacion de resultasdos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312516e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
